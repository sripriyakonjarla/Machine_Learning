{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sripriyakonjarla/Machine_Learning/blob/main/Stacking_classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygi-oUW1OwcQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier  # Example classifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "data = pd.read_excel('bart_embeddings.xlsx')\n",
        "\n",
        "# Assume the last column is the target variable\n",
        "X = data.iloc[:, :-1]  # Features\n",
        "y = data.iloc[:, -1]    # Target variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW4QfH95O1U7",
        "outputId": "02be84d1-7000-4cd1-e203-b7c70faa420e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdLcbYtO0moh",
        "outputId": "4a79a8fa-27ff-4482-8ea5-d36011ca42f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The actual and predicted values have been saved to 'predictions_output.xlsx'.\n",
            "Accuracy: 0.7571\n",
            "Precision: 0.7571\n",
            "Recall: 0.7571\n",
            "F1-score: 0.7571\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X, y)\n",
        "y_pred = knn.predict(X)\n",
        "# Create a DataFrame with actual and predicted values\n",
        "output_df = pd.DataFrame({\n",
        "    'Actual': y,\n",
        "    'Predicted': y_pred\n",
        "})\n",
        "# Save the DataFrame to an Excel file\n",
        "output_df.to_excel('predictions_output.xlsx', index=False)\n",
        "\n",
        "# Inform the user the file has been saved\n",
        "print(\"The actual and predicted values have been saved to 'predictions_output.xlsx'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6KC_1Sh3erU",
        "outputId": "5600ee42-465d-4edb-905f-7df06467bb15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The actual and predicted values have been saved to 'predictions_output.xlsx'.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "# Define the SVC model with default parameters\n",
        "svc = SVC(random_state=42)\n",
        "\n",
        "# Fit the model on the entire dataset\n",
        "svc.fit(X, y)\n",
        "# Print the evaluation metrics\n",
        "\n",
        "# Get predictions on the entire dataset\n",
        "y_pred = svc.predict(X)\n",
        "\n",
        "# Create a DataFrame with actual and predicted values\n",
        "output_df = pd.DataFrame({\n",
        "    'Actual': y,\n",
        "    'Predicted': y_pred\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_df.to_excel('predictions_output.xlsx', index=False)\n",
        "\n",
        "# Inform the user the file has been saved\n",
        "print(\"The actual and predicted values have been saved to 'predictions_output.xlsx'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8uhTn7R4ouE",
        "outputId": "3354ede5-9c44-45bd-b3d2-70772139975c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The actual and predicted values have been saved to 'predictions_output.xlsx'.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define the Decision Tree model\n",
        "dtc = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Fit the model on the entire dataset\n",
        "dtc.fit(X, y)\n",
        "\n",
        "# Get predictions on the entire dataset\n",
        "y_pred = dtc.predict(X)\n",
        "\n",
        "# Create a DataFrame with actual and predicted values\n",
        "output_df = pd.DataFrame({\n",
        "    'Actual': y,\n",
        "    'Predicted': y_pred\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_df.to_excel('predictions_output.xlsx', index=False)\n",
        "\n",
        "# Inform the user the file has been saved\n",
        "print(\"The actual and predicted values have been saved to 'predictions_output.xlsx'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJYIDycL5VeJ",
        "outputId": "94ce09af-c9d3-4ddf-a8a2-25c710f3af72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The actual and predicted values have been saved to 'predictions_output.xlsx'.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Define the Gaussian Naive Bayes model\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# Fit the model on the entire dataset\n",
        "gnb.fit(X, y)\n",
        "\n",
        "\n",
        "# Get predictions on the entire dataset\n",
        "y_pred = gnb.predict(X)\n",
        "\n",
        "# Create a DataFrame with actual and predicted values\n",
        "output_df = pd.DataFrame({\n",
        "    'Actual': y,\n",
        "    'Predicted': y_pred\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_df.to_excel('predictions_output.xlsx', index=False)\n",
        "\n",
        "# Inform the user the file has been saved\n",
        "print(\"The actual and predicted values have been saved to 'predictions_output.xlsx'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQDttvBA6HnW",
        "outputId": "e895c851-aad9-424c-894e-1e71b6770581"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The actual and predicted values have been saved to 'predictions_output.xlsx'.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Define the Random Forest model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Fit the model on the entire dataset\n",
        "rf.fit(X, y)\n",
        "\n",
        "\n",
        "# Get predictions on the entire dataset\n",
        "y_pred = rf.predict(X)\n",
        "\n",
        "# Create a DataFrame with actual and predicted values\n",
        "output_df = pd.DataFrame({\n",
        "    'Actual': y,\n",
        "    'Predicted': y_pred\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_df.to_excel('predictions_output.xlsx', index=False)\n",
        "\n",
        "# Inform the user the file has been saved\n",
        "print(\"The actual and predicted values have been saved to 'predictions_output.xlsx'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7otdgAsr7cKa",
        "outputId": "e6ba5258-f286-4622-b6b5-c36fca1ea771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The actual and predicted values have been saved to 'predictions_output.xlsx'.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# Fit the model on the entire dataset\n",
        "lr.fit(X, y)\n",
        "# Get predictions on the entire dataset\n",
        "y_pred = lr.predict(X)\n",
        "\n",
        "# Create a DataFrame with actual and predicted values\n",
        "output_df = pd.DataFrame({\n",
        "    'Actual': y,\n",
        "    'Predicted': y_pred\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_df.to_excel('predictions_output.xlsx', index=False)\n",
        "\n",
        "# Inform the user the file has been saved\n",
        "print(\"The actual and predicted values have been saved to 'predictions_output.xlsx'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orH8S4qv7pyb",
        "outputId": "35d5ccb3-49d2-4a64-cd2b-1cfee202877b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The actual and predicted values have been saved to 'predictions_output.xlsx'.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Define the MLP Classifier model\n",
        "mlp = MLPClassifier(random_state=42, max_iter=1000)\n",
        "\n",
        "# Fit the model on the entire dataset\n",
        "mlp.fit(X, y)\n",
        "\n",
        "# Get predictions on the entire dataset\n",
        "y_pred = mlp.predict(X)\n",
        "\n",
        "# Create a DataFrame with actual and predicted values\n",
        "output_df = pd.DataFrame({\n",
        "    'Actual': y,\n",
        "    'Predicted': y_pred\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_df.to_excel('predictions_output.xlsx', index=False)\n",
        "\n",
        "# Inform the user the file has been saved\n",
        "print(\"The actual and predicted values have been saved to 'predictions_output.xlsx'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PD4dQyw7tQz",
        "outputId": "309000b1-2fad-460a-8b86-c7895380af4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The actual and predicted values have been saved to 'predictions_output.xlsx'.\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "xgb = XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
        "\n",
        "# Fit the model on the entire dataset\n",
        "xgb.fit(X, y)\n",
        "\n",
        "# Get predictions on the entire dataset\n",
        "y_pred = xgb.predict(X)\n",
        "\n",
        "# Create a DataFrame with actual and predicted values\n",
        "output_df = pd.DataFrame({\n",
        "    'Actual': y,\n",
        "    'Predicted': y_pred\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_df.to_excel('predictions_output.xlsx', index=False)\n",
        "\n",
        "# Inform the user the file has been saved\n",
        "print(\"The actual and predicted values have been saved to 'predictions_output.xlsx'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QUNsLoL89SWH",
        "outputId": "bcbab6dd-adcd-421f-e2d9-b30b90e759ad"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Per-column arrays must each be 1-dimensional",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-64fbcccf8509>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Create a DataFrame with actual and predicted values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m output_df = pd.DataFrame({\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;34m'Actual'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m'Predicted'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0mraw_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Per-column arrays must each be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# Define the CatBoostClassifier model\n",
        "catboost_model = CatBoostClassifier(\n",
        "    random_seed=42,\n",
        "    iterations=1000,\n",
        "    learning_rate=0.1,\n",
        "    depth=6,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Fit the model on the entire dataset\n",
        "catboost_model.fit(X, y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzzVIgeOLWW-",
        "outputId": "46e63c35-c493-42b6-91a7-5a96b75769ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The actual and predicted values have been saved to 'predictions_output.xlsx'.\n"
          ]
        }
      ],
      "source": [
        "y_pred = catboost_model.predict(X)\n",
        "y_pred = y_pred.flatten()\n",
        "output_df = pd.DataFrame({\n",
        "    'Actual': y,\n",
        "    'Predicted': y_pred\n",
        "})\n",
        "output_df.to_excel('predictions_output.xlsx', index=False)\n",
        "print(\"The actual and predicted values have been saved to 'predictions_output.xlsx'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MdS80Ad9QSF",
        "outputId": "f43aba82-7450-402d-d045-c62e546f0bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The actual and predicted values have been saved to 'predictions_output.xlsx'.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Define the base estimator (Decision Tree) for AdaBoost\n",
        "base_estimator = DecisionTreeClassifier(max_depth=1)  # You can adjust the depth\n",
        "\n",
        "# Define the AdaBoost model\n",
        "ada_model = AdaBoostClassifier(\n",
        "    estimator=base_estimator,\n",
        "    n_estimators=100,       # Number of boosting stages to be run\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the model on the entire dataset\n",
        "ada_model.fit(X, y)\n",
        "\n",
        "# Get predictions on the entire dataset\n",
        "y_pred = ada_model.predict(X)\n",
        "\n",
        "# Create a DataFrame with actual and predicted values\n",
        "output_df = pd.DataFrame({\n",
        "    'Actual': y,\n",
        "    'Predicted': y_pred\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_df.to_excel('predictions_output.xlsx', index=False)\n",
        "\n",
        "# Inform the user the file has been saved\n",
        "print(\"The actual and predicted values have been saved to 'predictions_output.xlsx'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDls6K9x9V9-",
        "outputId": "ad1cfa91-f59a-4eb7-e0f2-393dc8aa8509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The actual and predicted values have been saved to 'predictions_output.xlsx'.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, cross_validate\n",
        "\n",
        "# Define the ExtraTreesClassifier model\n",
        "et_model = ExtraTreesClassifier(\n",
        "    random_state=42,\n",
        "    n_estimators=100,\n",
        "    max_features='sqrt',\n",
        ")\n",
        "\n",
        "# Fit the model on the entire dataset\n",
        "et_model.fit(X, y)\n",
        "\n",
        "\n",
        "# Get predictions on the entire dataset\n",
        "y_pred = et_model.predict(X)\n",
        "\n",
        "# Create a DataFrame with actual and predicted values\n",
        "output_df = pd.DataFrame({\n",
        "    'Actual': y,\n",
        "    'Predicted': y_pred\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_df.to_excel('predictions_output.xlsx', index=False)\n",
        "\n",
        "# Inform the user the file has been saved\n",
        "print(\"The actual and predicted values have been saved to 'predictions_output.xlsx'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiIZuEnP9fUb",
        "outputId": "2f035ab5-da03-43ac-acc0-bbb51215ecd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The actual and predicted values have been saved to 'predictions_output.xlsx'.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, cross_validate\n",
        "\n",
        "gb_model = GradientBoostingClassifier(\n",
        "    random_state=42,\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        ")\n",
        "\n",
        "# Fit the model on the entire dataset\n",
        "gb_model.fit(X, y)\n",
        "\n",
        "# Get predictions on the entire dataset\n",
        "y_pred = gb_model.predict(X)\n",
        "\n",
        "# Create a DataFrame with actual and predicted values\n",
        "output_df = pd.DataFrame({\n",
        "    'Actual': y,\n",
        "    'Predicted': y_pred\n",
        "})\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_df.to_excel('predictions_output.xlsx', index=False)\n",
        "\n",
        "# Inform the user the file has been saved\n",
        "print(\"The actual and predicted values have been saved to 'predictions_output.xlsx'.\")#29"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOHm_ro3NsOW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "data = pd.read_excel('basemodels.xlsx')\n",
        "# Assume the last column is the target variable\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd4_501QPS44"
      },
      "outputs": [],
      "source": [
        "data2 = pd.read_excel('testing_basemodels.xlsx')\n",
        "# Assume the last column is the target variable\n",
        "X_new = data2.iloc[:, :-1]  # Features\n",
        "y_new = data2.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define the KNN model with default parameters and class balancing (if needed)\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Step 1: Perform cross-validation on the KNN model\n",
        "cv_score = cross_validate(knn, X, y, cv=10,\n",
        "                          scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'],\n",
        "                          return_train_score=False)\n",
        "\n",
        "# Collect and round the results\n",
        "results = {\n",
        "    'Accuracy Mean': round(cv_score['test_accuracy'].mean(), 4),\n",
        "    'Accuracy STD': round(cv_score['test_accuracy'].std(), 4),\n",
        "    'Precision Mean': round(cv_score['test_precision_macro'].mean(), 4),\n",
        "    'Precision STD': round(cv_score['test_precision_macro'].std(), 4),\n",
        "    'Recall Mean': round(cv_score['test_recall_macro'].mean(), 4),\n",
        "    'Recall STD': round(cv_score['test_recall_macro'].std(), 4),\n",
        "    'F1 Mean': round(cv_score['test_f1_macro'].mean(), 4),\n",
        "    'F1 STD': round(cv_score['test_f1_macro'].std(), 4),\n",
        "}\n",
        "\n",
        "# Print the cross-validation evaluation metrics\n",
        "print(\"Cross-Validation Metrics (Training Data):\", results)\n",
        "\n",
        "# Step 2: Train the model on the entire dataset\n",
        "knn.fit(X, y)\n",
        "\n",
        "# Step 3: Perform predictions on new data\n",
        "y_pred = knn.predict(X_new)\n",
        "\n",
        "# Calculate metrics for the new data\n",
        "accuracy = accuracy_score(y_new, y_pred)\n",
        "precision = precision_score(y_new, y_pred)\n",
        "recall = recall_score(y_new, y_pred)\n",
        "f1 = f1_score(y_new, y_pred)\n",
        "\n",
        "# Print the evaluation metrics for the new data\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIcfjxWj8HR5",
        "outputId": "68b12e6d-6743-461a-812a-03d3605a93d5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Evaluation Metrics (Cross-Validation): {'Accuracy Mean': 0.9426, 'Accuracy STD': 0.038, 'Precision Mean': 0.9435, 'Precision STD': 0.0371, 'Recall Mean': 0.9326, 'Recall STD': 0.038, 'F1 Mean': 0.9425, 'F1 STD': 0.0381}\n",
            "Accuracy on New Data: 0.8443\n",
            "Precision on New Data: 0.8304\n",
            "Recall on New Data: 0.8343\n",
            "F1-score on New Data: 0.8340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "svc = SVC(random_state=42)\n",
        "\n",
        "# Step 1: Perform cross-validation on the SVC model\n",
        "cv_score = cross_validate(svc, X, y, cv=10,\n",
        "                          scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'],\n",
        "                          return_train_score=False)\n",
        "\n",
        "# Collect and round the results\n",
        "results = {\n",
        "    'Accuracy Mean': round(cv_score['test_accuracy'].mean(), 4),\n",
        "    'Accuracy STD': round(cv_score['test_accuracy'].std(), 4),\n",
        "    'Precision Mean': round(cv_score['test_precision_macro'].mean(), 4),\n",
        "    'Precision STD': round(cv_score['test_precision_macro'].std(), 4),\n",
        "    'Recall Mean': round(cv_score['test_recall_macro'].mean(), 4),\n",
        "    'Recall STD': round(cv_score['test_recall_macro'].std(), 4),\n",
        "    'F1 Mean': round(cv_score['test_f1_macro'].mean(), 4),\n",
        "    'F1 STD': round(cv_score['test_f1_macro'].std(), 4),\n",
        "}\n",
        "\n",
        "# Print the cross-validation evaluation metrics\n",
        "print(\"Cross-Validation Metrics (Training Data):\", results)\n",
        "\n",
        "# Step 2: Train the model on the entire dataset\n",
        "svc.fit(X, y)\n",
        "\n",
        "# Step 3: Perform predictions on new data\n",
        "y_pred = svc.predict(X_new)\n",
        "\n",
        "# Calculate metrics for the new data\n",
        "accuracy = accuracy_score(y_new, y_pred)\n",
        "precision = precision_score(y_new, y_pred)\n",
        "recall = recall_score(y_new, y_pred)\n",
        "f1 = f1_score(y_new, y_pred)\n",
        "\n",
        "# Print the evaluation metrics for the new data\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZgQW9CZ8hLm",
        "outputId": "c386cacf-8447-403d-d52e-da96eede8d6d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC Evaluation Metrics (Cross-Validation): {'Accuracy Mean': 0.9649, 'Accuracy STD': 0.0246, 'Precision Mean': 0.97, 'Precision STD': 0.0239, 'Recall Mean': 0.9667, 'Recall STD': 0.0254, 'F1 Mean': 0.9674, 'F1 STD': 0.025}\n",
            "Accuracy on New Data: 0.8923\n",
            "Precision on New Data: 0.8904\n",
            "Recall on New Data: 0.8903\n",
            "F1-score on New Data: 0.8904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2lN_XezPFV_",
        "outputId": "5f8c0a6c-8932-4583-827b-c04cf510853d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Metrics (Training Data): {'Accuracy Mean': 0.9583, 'Accuracy STD': 0.0231, 'Precision Mean': 0.9608, 'Precision STD': 0.0226, 'Recall Mean': 0.9584, 'Recall STD': 0.0229, 'F1 Mean': 0.9582, 'F1 STD': 0.0229}\n",
            "Accuracy: 0.8000\n",
            "Precision: 0.8297\n",
            "Recall: 0.8000\n",
            "F1-score: 0.8019\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define the Decision Tree model with default parameters and class balancing\n",
        "dtree = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
        "\n",
        "# Step 1: Perform cross-validation on the Decision Tree model\n",
        "cv_score = cross_validate(dtree, X, y, cv=10,\n",
        "                          scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'],\n",
        "                          return_train_score=False)\n",
        "\n",
        "# Collect and round the results\n",
        "results = {\n",
        "    'Accuracy Mean': round(cv_score['test_accuracy'].mean(), 4),\n",
        "    'Accuracy STD': round(cv_score['test_accuracy'].std(), 4),\n",
        "    'Precision Mean': round(cv_score['test_precision_macro'].mean(), 4),\n",
        "    'Precision STD': round(cv_score['test_precision_macro'].std(), 4),\n",
        "    'Recall Mean': round(cv_score['test_recall_macro'].mean(), 4),\n",
        "    'Recall STD': round(cv_score['test_recall_macro'].std(), 4),\n",
        "    'F1 Mean': round(cv_score['test_f1_macro'].mean(), 4),\n",
        "    'F1 STD': round(cv_score['test_f1_macro'].std(), 4),\n",
        "}\n",
        "\n",
        "# Print the cross-validation evaluation metrics\n",
        "print(\"Cross-Validation Metrics (Training Data):\", results)\n",
        "\n",
        "# Step 2: Train the model on the entire dataset\n",
        "dtree.fit(X, y)\n",
        "\n",
        "# Step 3: Perform predictions on new data\n",
        "y_pred = dtree.predict(X_new)\n",
        "\n",
        "# Calculate metrics for the new data\n",
        "accuracy = accuracy_score(y_new, y_pred)\n",
        "precision = precision_score(y_new, y_pred)\n",
        "recall = recall_score(y_new, y_pred)\n",
        "f1 = f1_score(y_new, y_pred)\n",
        "\n",
        "# Print the evaluation metrics for the new data\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Initialize the Naive Bayes model\n",
        "nb = GaussianNB(var_smoothing=1e-9)\n",
        "\n",
        "nb.fit(X, y)\n",
        "\n",
        "\n",
        "cv_score = cross_validate(nb, X, y, cv=10,\n",
        "                          scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'],\n",
        "                          return_train_score=False)\n",
        "\n",
        "# Collect and round the results\n",
        "results = {\n",
        "    'Accuracy Mean': round(cv_score['test_accuracy'].mean(), 4),\n",
        "    'Accuracy STD': round(cv_score['test_accuracy'].std(), 4),\n",
        "    'Precision Mean': round(cv_score['test_precision_macro'].mean(), 4),\n",
        "    'Precision STD': round(cv_score['test_precision_macro'].std(), 4),\n",
        "    'Recall Mean': round(cv_score['test_recall_macro'].mean(), 4),\n",
        "    'Recall STD': round(cv_score['test_recall_macro'].std(), 4),\n",
        "    'F1 Mean': round(cv_score['test_f1_macro'].mean(), 4),\n",
        "    'F1 STD': round(cv_score['test_f1_macro'].std(), 4),\n",
        "}\n",
        "\n",
        "# Print the cross-validation results\n",
        "print(\"Naive Bayes Evaluation Metrics:\", results)\n",
        "\n",
        "# Prediction on new data (make sure you define X_new and y_new)\n",
        "y_pred = nb.predict(X_new)  # Corrected this line\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_new, y_pred)\n",
        "precision = precision_score(y_new, y_pred)\n",
        "recall = recall_score(y_new, y_pred)\n",
        "f1 = f1_score(y_new, y_pred)\n",
        "\n",
        "# Print the evaluation metrics on the new data\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArTnk8fD5qT6",
        "outputId": "6ece7b28-2494-40a1-afa9-16a10401099e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive bayes Evaluation Metrics (Cross-Validation): {'Accuracy Mean': 0.9226, 'Accuracy STD': 0.0413, 'Precision Mean': 0.9242, 'Precision STD': 0.0498, 'Recall Mean': 0.922, 'Recall STD': 0.0422, 'F1 Mean': 0.9224, 'F1 STD': 0.0412}\n",
            "Accuracy on New Data: 0.8286\n",
            "Precision on New Data: 0.8658\n",
            "Recall on New Data: 0.8286\n",
            "F1-score on New Data: 0.8267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIMywLa7P7rw",
        "outputId": "1be4f209-5265-4add-86db-cc31484d8af5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics (Cross-Validation): {'Accuracy Mean': 0.9607, 'Accuracy STD': 0.0235, 'Precision Mean': 0.9632, 'Precision STD': 0.0226, 'Recall Mean': 0.9604, 'Recall STD': 0.0237, 'F1 Mean': 0.9606, 'F1 STD': 0.0234}\n",
            "Accuracy on New Data: 0.8857\n",
            "Precision on New Data: 0.9126\n",
            "Recall on New Data: 0.8857\n",
            "F1-score on New Data: 0.8845\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define the Random Forest model (using default parameters)\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform cross-validation (StratifiedKFold to preserve class distribution)\n",
        "cv_score = cross_validate(rf, X, y, cv=10,\n",
        "                          scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'],\n",
        "                          return_train_score=False)\n",
        "\n",
        "# Collect and round the results\n",
        "results = {\n",
        "    'Accuracy Mean': round(cv_score['test_accuracy'].mean(), 4),\n",
        "    'Accuracy STD': round(cv_score['test_accuracy'].std(), 4),\n",
        "    'Precision Mean': round(cv_score['test_precision_macro'].mean(), 4),\n",
        "    'Precision STD': round(cv_score['test_precision_macro'].std(), 4),\n",
        "    'Recall Mean': round(cv_score['test_recall_macro'].mean(), 4),\n",
        "    'Recall STD': round(cv_score['test_recall_macro'].std(), 4),\n",
        "    'F1 Mean': round(cv_score['test_f1_macro'].mean(), 4),\n",
        "    'F1 STD': round(cv_score['test_f1_macro'].std(), 4),\n",
        "}\n",
        "\n",
        "# Print the evaluation metrics from cross-validation\n",
        "print(\"Evaluation Metrics (Cross-Validation):\", results)\n",
        "\n",
        "# Step 4: Train the Random Forest model on the entire training dataset\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Step 5: Prediction on new data (X_new, y_new should already be defined)\n",
        "y_pred = rf.predict(X_new)\n",
        "\n",
        "# Calculate metrics for the new data\n",
        "accuracy = accuracy_score(y_new, y_pred)\n",
        "precision = precision_score(y_new, y_pred)\n",
        "recall = recall_score(y_new, y_pred)\n",
        "f1 = f1_score(y_new, y_pred)\n",
        "\n",
        "# Print the evaluation metrics for new data\n",
        "print(f\"Accuracy on New Data: {accuracy:.4f}\")\n",
        "print(f\"Precision on New Data: {precision:.4f}\")\n",
        "print(f\"Recall on New Data: {recall:.4f}\")\n",
        "print(f\"F1-score on New Data: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5UE1-OBQGPH",
        "outputId": "5cea7014-23f2-45fd-e80e-05a40e45a8d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Evaluation Metrics (Cross-Validation): {'Accuracy Mean': 0.9702, 'Accuracy STD': 0.021, 'Precision Mean': 0.9727, 'Precision STD': 0.0189, 'Recall Mean': 0.9698, 'Recall STD': 0.0214, 'F1 Mean': 0.9704, 'F1 STD': 0.0206}\n",
            "Accuracy on New Data: 0.8286\n",
            "Precision on New Data: 0.8658\n",
            "Recall on New Data: 0.8286\n",
            "F1-score on New Data: 0.8267\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define the Logistic Regression model with default parameters\n",
        "log_reg = LogisticRegression(random_state=42)\n",
        "\n",
        "# Perform cross-validation using StratifiedKFold to preserve class distribution\n",
        "cv_score = cross_validate(log_reg, X, y, cv=10,\n",
        "                          scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'],\n",
        "                          return_train_score=False)\n",
        "\n",
        "# Collect and round the results\n",
        "results = {\n",
        "    'Accuracy Mean': round(cv_score['test_accuracy'].mean(), 4),\n",
        "    'Accuracy STD': round(cv_score['test_accuracy'].std(), 4),\n",
        "    'Precision Mean': round(cv_score['test_precision_macro'].mean(), 4),\n",
        "    'Precision STD': round(cv_score['test_precision_macro'].std(), 4),\n",
        "    'Recall Mean': round(cv_score['test_recall_macro'].mean(), 4),\n",
        "    'Recall STD': round(cv_score['test_recall_macro'].std(), 4),\n",
        "    'F1 Mean': round(cv_score['test_f1_macro'].mean(), 4),\n",
        "    'F1 STD': round(cv_score['test_f1_macro'].std(), 4),\n",
        "}\n",
        "\n",
        "# Print the evaluation metrics from cross-validation\n",
        "print(\"Logistic Regression Evaluation Metrics (Cross-Validation):\", results)\n",
        "\n",
        "# Train the Logistic Regression model on the entire training dataset\n",
        "log_reg.fit(X, y)\n",
        "\n",
        "# Step 5: Prediction on new data (X_new, y_new should already be defined)\n",
        "y_pred = log_reg.predict(X_new)\n",
        "\n",
        "# Calculate metrics for the new data\n",
        "accuracy = accuracy_score(y_new, y_pred)\n",
        "precision = precision_score(y_new, y_pred)\n",
        "recall = recall_score(y_new, y_pred)\n",
        "f1 = f1_score(y_new, y_pred)\n",
        "\n",
        "# Print the evaluation metrics for new data\n",
        "print(f\"Accuracy on New Data: {accuracy:.4f}\")\n",
        "print(f\"Precision on New Data: {precision:.4f}\")\n",
        "print(f\"Recall on New Data: {recall:.4f}\")\n",
        "print(f\"F1-score on New Data: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWFPooNVQM7i",
        "outputId": "6ebea0b0-9535-4b8c-cbc7-b3bfbc9260f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Evaluation Metrics (Cross-Validation): {'Accuracy Mean': 0.9637, 'Accuracy STD': 0.0253, 'Precision Mean': 0.9663, 'Precision STD': 0.0246, 'Recall Mean': 0.9634, 'Recall STD': 0.0245, 'F1 Mean': 0.9637, 'F1 STD': 0.0251}\n",
            "Accuracy on New Data: 0.8286\n",
            "Precision on New Data: 0.8658\n",
            "Recall on New Data: 0.8286\n",
            "F1-score on New Data: 0.8267\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "mlp = MLPClassifier( random_state=42)\n",
        "\n",
        "# Perform cross-validation to evaluate the model\n",
        "cv_score = cross_validate(mlp, X, y, cv=10,\n",
        "                          scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'],\n",
        "                          return_train_score=False)\n",
        "\n",
        "# Collect and round the results\n",
        "results = {\n",
        "    'Accuracy Mean': round(cv_score['test_accuracy'].mean(), 4),\n",
        "    'Accuracy STD': round(cv_score['test_accuracy'].std(), 4),\n",
        "    'Precision Mean': round(cv_score['test_precision_macro'].mean(), 4),\n",
        "    'Precision STD': round(cv_score['test_precision_macro'].std(), 4),\n",
        "    'Recall Mean': round(cv_score['test_recall_macro'].mean(), 4),\n",
        "    'Recall STD': round(cv_score['test_recall_macro'].std(), 4),\n",
        "    'F1 Mean': round(cv_score['test_f1_macro'].mean(), 4),\n",
        "    'F1 STD': round(cv_score['test_f1_macro'].std(), 4),\n",
        "}\n",
        "\n",
        "# Print the evaluation metrics from cross-validation\n",
        "print(\"MLP Evaluation Metrics (Cross-Validation):\", results)\n",
        "\n",
        "# Train the model on the full training data\n",
        "mlp.fit(X, y)\n",
        "\n",
        "# Step 5: Prediction on new data (X_new, y_new should already be defined)\n",
        "y_pred = mlp.predict(X_new)\n",
        "\n",
        "# Calculate metrics for the new data\n",
        "accuracy = accuracy_score(y_new, y_pred)\n",
        "precision = precision_score(y_new, y_pred)\n",
        "recall = recall_score(y_new, y_pred)\n",
        "f1 = f1_score(y_new, y_pred)\n",
        "\n",
        "# Print the evaluation metrics for the new data\n",
        "print(f\"Accuracy on New Data: {accuracy:.4f}\")\n",
        "print(f\"Precision on New Data: {precision:.4f}\")\n",
        "print(f\"Recall on New Data: {recall:.4f}\")\n",
        "print(f\"F1-score on New Data: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define the XGBoost model with default parameters\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "\n",
        "# Perform cross-validation to evaluate the model\n",
        "cv_score = cross_validate(xgb, X, y, cv=10,\n",
        "                          scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'],\n",
        "                          return_train_score=False)\n",
        "\n",
        "# Collect and round the results\n",
        "results = {\n",
        "    'Accuracy Mean': round(cv_score['test_accuracy'].mean(), 4),\n",
        "    'Accuracy STD': round(cv_score['test_accuracy'].std(), 4),\n",
        "    'Precision Mean': round(cv_score['test_precision_macro'].mean(), 4),\n",
        "    'Precision STD': round(cv_score['test_precision_macro'].std(), 4),\n",
        "    'Recall Mean': round(cv_score['test_recall_macro'].mean(), 4),\n",
        "    'Recall STD': round(cv_score['test_recall_macro'].std(), 4),\n",
        "    'F1 Mean': round(cv_score['test_f1_macro'].mean(), 4),\n",
        "    'F1 STD': round(cv_score['test_f1_macro'].std(), 4),\n",
        "}\n",
        "\n",
        "# Print the evaluation metrics from cross-validation\n",
        "print(\"XGBoost Evaluation Metrics (Cross-Validation):\", results)\n",
        "\n",
        "# Train the model on the full training data\n",
        "xgb.fit(X, y)\n",
        "\n",
        "# Step 5: Prediction on new data (X_new, y_new should already be defined)\n",
        "y_pred = xgb.predict(X_new)\n",
        "\n",
        "# Calculate metrics for the new data\n",
        "accuracy = accuracy_score(y_new, y_pred)\n",
        "precision = precision_score(y_new, y_pred)\n",
        "recall = recall_score(y_new, y_pred)\n",
        "f1 = f1_score(y_new, y_pred)\n",
        "\n",
        "# Print the evaluation metrics for the new data\n",
        "print(f\"Accuracy on New Data: {accuracy:.4f}\")\n",
        "print(f\"Precision on New Data: {precision:.4f}\")\n",
        "print(f\"Recall on New Data: {recall:.4f}\")\n",
        "print(f\"F1-score on New Data: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIHknOJd4UEK",
        "outputId": "3a745ca9-c9ec-429d-ccc4-a7a6a45e3f9d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Evaluation Metrics (Cross-Validation): {'Accuracy Mean': 0.9789, 'Accuracy STD': 0.023, 'Precision Mean': 0.9613, 'Precision STD': 0.0224, 'Recall Mean': 0.9789, 'Recall STD': 0.0285, 'F1 Mean': 0.9788, 'F1 STD': 0.0228}\n",
            "Accuracy on New Data: 0.9143\n",
            "Precision on New Data: 0.9130\n",
            "Recall on New Data: 0.9110\n",
            "F1-score on New Data: 0.9104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttXwsreNQgSF",
        "outputId": "4d982d87-a98c-4fd7-d80e-95975d1017dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CatBoost Evaluation Metrics (Cross-Validation): {'Accuracy Mean': 0.9595, 'Accuracy STD': 0.023, 'Precision Mean': 0.9619, 'Precision STD': 0.0223, 'Recall Mean': 0.9594, 'Recall STD': 0.0231, 'F1 Mean': 0.9594, 'F1 STD': 0.0228}\n",
            "Accuracy on New Data: 0.8571\n",
            "Precision on New Data: 0.8821\n",
            "Recall on New Data: 0.8571\n",
            "F1-score on New Data: 0.8567\n"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define the CatBoost model with default parameters\n",
        "catboost = CatBoostClassifier(silent=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation to evaluate the model\n",
        "cv_score = cross_validate(catboost, X, y, cv=10,\n",
        "                          scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'],\n",
        "                          return_train_score=False)\n",
        "\n",
        "# Collect and round the results\n",
        "results = {\n",
        "    'Accuracy Mean': round(cv_score['test_accuracy'].mean(), 4),\n",
        "    'Accuracy STD': round(cv_score['test_accuracy'].std(), 4),\n",
        "    'Precision Mean': round(cv_score['test_precision_macro'].mean(), 4),\n",
        "    'Precision STD': round(cv_score['test_precision_macro'].std(), 4),\n",
        "    'Recall Mean': round(cv_score['test_recall_macro'].mean(), 4),\n",
        "    'Recall STD': round(cv_score['test_recall_macro'].std(), 4),\n",
        "    'F1 Mean': round(cv_score['test_f1_macro'].mean(), 4),\n",
        "    'F1 STD': round(cv_score['test_f1_macro'].std(), 4),\n",
        "}\n",
        "\n",
        "# Print the evaluation metrics from cross-validation\n",
        "print(\"CatBoost Evaluation Metrics (Cross-Validation):\", results)\n",
        "\n",
        "# Train the model on the full training data\n",
        "catboost.fit(X, y)\n",
        "\n",
        "# Step 5: Prediction on new data (X_new, y_new should already be defined)\n",
        "y_pred = catboost.predict(X_new)\n",
        "\n",
        "# Calculate metrics for the new data\n",
        "accuracy = accuracy_score(y_new, y_pred)\n",
        "precision = precision_score(y_new, y_pred, average='weighted')\n",
        "recall = recall_score(y_new, y_pred, average='weighted')\n",
        "f1 = f1_score(y_new, y_pred, average='weighted')\n",
        "\n",
        "# Print the evaluation metrics for the new data\n",
        "print(f\"Accuracy on New Data: {accuracy:.4f}\")\n",
        "print(f\"Precision on New Data: {precision:.4f}\")\n",
        "print(f\"Recall on New Data: {recall:.4f}\")\n",
        "print(f\"F1-score on New Data: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Step 3: Define the AdaBoost model with a shallow decision tree as the base estimator\n",
        "base_estimator = DecisionTreeClassifier( random_state=42)\n",
        "\n",
        "ada = AdaBoostClassifier(\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Step 4: Perform cross-validation on the AdaBoost model with default parameters\n",
        "cv_score = cross_validate(\n",
        "    ada, X, y, cv=10, scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'], return_train_score=False\n",
        ")\n",
        "\n",
        "# Step 5: Collect and round the results from cross-validation\n",
        "results = {\n",
        "    'Accuracy Mean': round(cv_score['test_accuracy'].mean(), 4),\n",
        "    'Accuracy STD': round(cv_score['test_accuracy'].std(), 4),\n",
        "    'Precision Mean': round(cv_score['test_precision_macro'].mean(), 4),\n",
        "    'Precision STD': round(cv_score['test_precision_macro'].std(), 4),\n",
        "    'Recall Mean': round(cv_score['test_recall_macro'].mean(), 4),\n",
        "    'Recall STD': round(cv_score['test_recall_macro'].std(), 4),\n",
        "    'F1 Mean': round(cv_score['test_f1_macro'].mean(), 4),\n",
        "    'F1 STD': round(cv_score['test_f1_macro'].std(), 4),\n",
        "}\n",
        "\n",
        "# Print the evaluation metrics from cross-validation\n",
        "print(\"AdaBoost Evaluation Metrics (Cross-Validation):\", results)\n",
        "\n",
        "# Step 6: Train the AdaBoost model on the full training data\n",
        "ada.fit(X, y)\n",
        "\n",
        "# Step 7: Prediction on new data (X_new, y_new should already be defined)\n",
        "y_pred = ada.predict(X_new)\n",
        "\n",
        "# Step 8: Calculate metrics for the new data\n",
        "accuracy = accuracy_score(y_new, y_pred)\n",
        "precision = precision_score(y_new, y_pred)\n",
        "recall = recall_score(y_new, y_pred)\n",
        "f1 = f1_score(y_new, y_pred)\n",
        "\n",
        "# Print the evaluation metrics for the new data\n",
        "print(f\"Accuracy on New Data: {accuracy:.4f}\")\n",
        "print(f\"Precision on New Data: {precision:.4f}\")\n",
        "print(f\"Recall on New Data: {recall:.4f}\")\n",
        "print(f\"F1-score on New Data: {f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7RlsFyF3usU",
        "outputId": "feecb073-0681-4750-a421-43795f9740f3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Evaluation Metrics (Cross-Validation): {'Accuracy Mean': 0.9473, 'Accuracy STD': 0.0207, 'Precision Mean': 0.9473, 'Precision STD': 0.0215, 'Recall Mean': 0.9491, 'Recall STD': 0.0185, 'F1 Mean': 0.9474, 'F1 STD': 0.0204}\n",
            "Accuracy on New Data: 0.8286\n",
            "Precision on New Data: 0.8565\n",
            "Recall on New Data: 0.8286\n",
            "F1-score on New Data: 0.8295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define the Extra Trees model with default parameters\n",
        "extra_trees_model = ExtraTreesClassifier(random_state=42)\n",
        "\n",
        "# Perform cross-validation on the Extra Trees model with default parameters\n",
        "cv_score = cross_validate(\n",
        "    extra_trees_model, X, y, cv=10, scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'], return_train_score=False\n",
        ")\n",
        "\n",
        "# Collect and round the results from cross-validation\n",
        "results = {\n",
        "    'Accuracy Mean': round(cv_score['test_accuracy'].mean(), 4),\n",
        "    'Accuracy STD': round(cv_score['test_accuracy'].std(), 4),\n",
        "    'Precision Mean': round(cv_score['test_precision_macro'].mean(), 4),\n",
        "    'Precision STD': round(cv_score['test_precision_macro'].std(), 4),\n",
        "    'Recall Mean': round(cv_score['test_recall_macro'].mean(), 4),\n",
        "    'Recall STD': round(cv_score['test_recall_macro'].std(), 4),\n",
        "    'F1 Mean': round(cv_score['test_f1_macro'].mean(), 4),\n",
        "    'F1 STD': round(cv_score['test_f1_macro'].std(), 4),\n",
        "}\n",
        "\n",
        "# Print the evaluation metrics from cross-validation\n",
        "print(\"Extra Trees Evaluation Metrics (Cross-Validation):\", results)\n",
        "\n",
        "# Train the Extra Trees model on the full training data\n",
        "extra_trees_model.fit(X, y)\n",
        "\n",
        "# Prediction on new data (X_new, y_new should already be defined)\n",
        "y_pred = extra_trees_model.predict(X_new)\n",
        "\n",
        "# Calculate metrics for the new data\n",
        "accuracy = accuracy_score(y_new, y_pred)\n",
        "precision = precision_score(y_new, y_pred)\n",
        "recall = recall_score(y_new, y_pred)\n",
        "f1 = f1_score(y_new, y_pred)\n",
        "\n",
        "# Print the evaluation metrics for the new data\n",
        "print(f\"Accuracy on New Data: {accuracy:.4f}\")\n",
        "print(f\"Precision on New Data: {precision:.4f}\")\n",
        "print(f\"Recall on New Data: {recall:.4f}\")\n",
        "print(f\"F1-score on New Data: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReWtdf7y3LnZ",
        "outputId": "2d314061-7a3c-4c57-dc06-78e1023bf9ff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extra Trees Evaluation Metrics (Cross-Validation): {'Accuracy Mean': 0.9607, 'Accuracy STD': 0.0235, 'Precision Mean': 0.9632, 'Precision STD': 0.0226, 'Recall Mean': 0.9604, 'Recall STD': 0.0237, 'F1 Mean': 0.9606, 'F1 STD': 0.0234}\n",
            "Accuracy on New Data: 0.8801\n",
            "Precision on New Data: 0.8810\n",
            "Recall on New Data: 0.8943\n",
            "F1-score on New Data: 0.8904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define the Gradient Boosting model with default parameters\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Perform cross-validation on the Gradient Boosting model with default parameters\n",
        "cv_score = cross_validate(\n",
        "    gb_model, X, y, cv=10, scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'], return_train_score=False\n",
        ")\n",
        "\n",
        "# Collect and round the results from cross-validation\n",
        "results = {\n",
        "    'Accuracy Mean': round(cv_score['test_accuracy'].mean(), 4),\n",
        "    'Accuracy STD': round(cv_score['test_accuracy'].std(), 4),\n",
        "    'Precision Mean': round(cv_score['test_precision_macro'].mean(), 4),\n",
        "    'Precision STD': round(cv_score['test_precision_macro'].std(), 4),\n",
        "    'Recall Mean': round(cv_score['test_recall_macro'].mean(), 4),\n",
        "    'Recall STD': round(cv_score['test_recall_macro'].std(), 4),\n",
        "    'F1 Mean': round(cv_score['test_f1_macro'].mean(), 4),\n",
        "    'F1 STD': round(cv_score['test_f1_macro'].std(), 4),\n",
        "}\n",
        "\n",
        "# Print the evaluation metrics from cross-validation\n",
        "print(\"Gradient Boosting Evaluation Metrics (Cross-Validation):\", results)\n",
        "\n",
        "# Train the Gradient Boosting model on the full training data\n",
        "gb_model.fit(X, y)\n",
        "\n",
        "# Prediction on new data (X_new, y_new should already be defined)\n",
        "y_pred = gb_model.predict(X_new)\n",
        "\n",
        "# Calculate metrics for the new data\n",
        "accuracy = accuracy_score(y_new, y_pred)\n",
        "precision = precision_score(y_new, y_pred)\n",
        "recall = recall_score(y_new, y_pred)\n",
        "f1 = f1_score(y_new, y_pred)\n",
        "\n",
        "# Print the evaluation metrics for the new data\n",
        "print(f\"Accuracy on New Data: {accuracy:.4f}\")\n",
        "print(f\"Precision on New Data: {precision:.4f}\")\n",
        "print(f\"Recall on New Data: {recall:.4f}\")\n",
        "print(f\"F1-score on New Data: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvL6tYBI1Fjj",
        "outputId": "06d35f0d-ece4-421a-b61d-a6fbcca0c609"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Evaluation Metrics (Cross-Validation): {'Accuracy Mean': 0.9589, 'Accuracy STD': 0.023, 'Precision Mean': 0.9613, 'Precision STD': 0.0224, 'Recall Mean': 0.9589, 'Recall STD': 0.0229, 'F1 Mean': 0.9588, 'F1 STD': 0.0228}\n",
            "Accuracy on New Data: 0.8920\n",
            "Precision on New Data: 0.8904\n",
            "Recall on New Data: 0.8930\n",
            "F1-score on New Data: 0.8804\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcNBavzApHHjIcw+aDsXq6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}